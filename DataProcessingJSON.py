#Ignornig any warning while running the code.
import warnings
warnings.filterwarnings('ignore')

#Importing the libraries required 
import sys, os
from pathlib import Path
import pandas as pd
from datetime import datetime

import logging

# Extract only date from current timestamp to name the log file.

batch_date = str((datetime.now()).strftime('%Y-%m-%d')) 

# Logging sesson creation to write the logs

logging.basicConfig(filename='Batch_Log_{}.log'.format(batch_date),
                            filemode='w',
                            format='%(asctime)s %(levelname)s %(message)s',
                            datefmt='%Y-%m-%d %H:%M:%S',
                            level=logging.DEBUG)


logger = logging.getLogger(__name__)

# Function to write the output file in text format

def write_as_txt(f, df):
    with open(f, 'w') as f:
                f.write(df.to_string(index = False))

# Function to write the output file in csv format

def write_as_csv(f, df):
    df.to_csv(f, index=None)

# Function to write the output file in json format

def write_as_json(f, df):
    df.to_json(f, orient='records')

# Function to write the output file in excel/xlsx format
def write_as_excel(f, df):
    df.to_excel(f) 

"""
    Below function to read the json files from the given path.
    File names are assigned manually and also dynamic file read and naming is available.
    Data cleansing for the column data mismatch 
    creating a summarized file by mergning the two dataframes and dropping the null values

"""

def main(input_path):

    logger.info("starting the function")

    #input_path = '/Users/Downloads/Chicago_bird_collision_data'

    logger.debug("checking for json files in below folder path \n %s ", input_path)

    # List the filenames with json as extension to read from the folder

    try:
        file_list = list(filter(lambda x: '.json' in x, os.listdir(input_path)))

        logger.debug("There are %s json files with names listed below \n %s ", len(file_list), [x for x in file_list ])

    except Exception:
        logger.error("please enter the correct folder path and file format may be corrupted. please check and rerun")
           # Read the json files and create a dataframes with the filenames in the folder
    try:
        # Read the json files and create the dataframes from the files in the input folder

        chicago_collision_data = pd.read_json(input_path + '/' + str(file_list[0]))

        flight_call = pd.read_json(input_path + '/' + str(file_list[1]))

        light_levels = pd.read_json(input_path + '/' + str(file_list[2]))

        logger.info("Original dataframes are created")

        flight_call_clean = flight_call.rename(columns={"Species": "Genus", "Family": "Species"}, errors=False)

    # Summarize file is generated by merging the two dataframes

        summarized_finaldf = (
        chicago_collision_data
        .merge(flight_call_clean, how='inner')  # merge the collision dataframe with flights clean flight dataframe
    ).rename(columns= {"Collisions": "Family", "Call": "Flight Call"}).dropna()

        logger.info("Data frames merged and summarized dataframe is generated with below columns \n %s ", [x for x in summarized_finaldf.columns] )

    
    # cleaning the data, removing the extra characters from the summarized file. 
        summarized_finaldf['Stratum'] = summarized_finaldf['Stratum'].str.strip('\t')

    except Exception:
        logger.error("File format is not correct / Files not found please check and rerun the script.")
    

    return summarized_finaldf           

if __name__ == '__main__':

     #Giving input folder path to read the json files 
    print("Please enter the input folder path with '/' as separator")

        # Take the input folder path which the files are present
    input_path = input()


    try:

        print("Do you want to enter the output filename (yes or no)? ")
        yesornoinput = input()

        if yesornoinput == 'yes':

            print("please enter the outfolder name with file name and extenstion \n \
                The default output format is csv and if you want the outfile in different format please follow below \n \
                filename.json as extenstion for json output format \n \
                fiename.xlsx as extenstion for xlsx output format \n \
                filename.txt as extenstion for txt output format ")
            
            outputfilepath = input()

            #Split the path into head and tail to separate folder path and filename
            
            head, tail = ntpath.split(outputfilepath)
            filename = tail

        else:
            print("please enter the outfolder name") 

            outputfilepath = input()
            outputfilepath = os.path.join(outputfilepath, 'ouputsummary')

    except Exception:
        logging.error("File Extension is not available and will generate file with default format (ouputsummary.csv)")


    finaldf = main(input_path)

    try:

        if outputfilepath:       

            logger.info("The output filename taken as %s ", outputfilepath)

            try:
                if '.txt' in outputfilepath:

                    # Call Funciton to generate the output file in csv
                    write_as_txt(outputfilepath, finaldf)
                    logging.debug("Output Summarized file with text format is created")


                elif '.json' in outputfilepath:

                    # Call Funciton to generate the output file in csv
                    write_as_json(outputfilepath, finaldf)
                    logging.debug("Output Summarized file with json format is created")


                elif '.xlsx' in outputfilepath:
                    write_as_excel(outputfilepath, finaldf)
                    logging.debug("Output Summarized file with xlsx format is created")


                else:
                    # Call Funciton to generate the output file in csv
                    if '.csv' in outputfilepath:
                        write_as_csv(outputfilepath, finaldf)
                        logging.debug("Output Summarized file with csv format is created")
                        
                    else:
                        filename_csv = outputfilepath + '.csv'
                        write_as_csv(filename_csv, finaldf)
                        logging.debug("Output Summarized file with csv format is created with filename %s", filename_csv)
           
            except Exception:
                
                logging.error("Errors in writing the output file")

    except:

        logger.error("could not write file %s to destination", outputfilepath)
      # Shut down the logger
    logging.shutdown()

